# Lightweight Testing Strategy Design

**Date:** 2025-10-29
**Status:** Approved
**Goal:** Enable unattended single-session testing of all 31 MCP tools

## Problem Statement

User Testing hit Claude Desktop's conversation length limit at test 21/31 (68% through). Current testing prompt is too verbose, making complete testing impossible in a single session. This breaks the unattended testing workflow where User Testing needs to paste prompt and walk away.

## Requirements

1. **Primary:** Single-session unattended testing (paste and walk away)
2. **Coverage:** All 31 tools tested
3. **Debugging:** Detailed investigation for failures
4. **Acceptable:** 2-3 pre-planned sessions if single session proves impossible

## Solution: Two-Phase Auto-Transition Testing

### Architecture

**One Prompt, Two Phases:**
- **Phase 1:** Lightweight pass (all 31 tools, concise output)
- **Phase 2:** Automatic detailed investigation (failures only, triggered in same session)

### Phase 1: Lightweight Pass

**Output Format:**
```
‚úÖ Test N: tool_name(key_params) - brief_result
‚ùå Test N: tool_name - FAIL: one_line_error
‚ö†Ô∏è Test N: tool_name - WARNING: issue (e.g., slow query >10s)
```

**Included:**
- Pass/fail indicator
- Tool name + key parameters
- Brief result (count, success message)
- Timing only if > 10 seconds
- One-line error for failures

**Excluded:**
- Full JSON tool calls (except failures)
- Complete responses (except failures)
- Detailed analysis (except failures)
- Field-by-field validation (except failures)

**Token Budget:** ~15-20k tokens (vs current ~60-80k)

### Phase 2: Detailed Investigation (Auto-Triggered)

**Trigger Condition:** Phase 1 detects any failures or warnings

**Output for Each Failure:**
```markdown
üîç Test N: tool_name - DETAILED ANALYSIS

Tool Call: {full JSON}
Response: {relevant excerpt}
Issue Analysis: {root cause}
File Locations: {paths}
Recommendations: {specific fixes}
```

**Token Budget:** ~500-1000 tokens per failed test

### Token Estimates

**Successful run (no failures):**
- Phase 1: 15-20k tokens
- Claude responses: 20-30k tokens
- **Total: 35-50k tokens** ‚úÖ

**With failures (2-3 typical):**
- Phase 1: 15-20k tokens
- Phase 2: 2-3k tokens (3 failures √ó 1k each)
- Claude responses: 25-35k tokens
- **Total: 42-58k tokens** ‚úÖ

**Current baseline:** Hit limits at ~120-140k tokens (test 21/31)

## Implementation

### File: `docs/operational/TESTING_PROMPT_LIGHTWEIGHT.md`

Structure:
```markdown
# OmniFocus MCP Comprehensive Test Suite

## Instructions
- Phase 1: Run all 31 tests with lightweight format
- Phase 2: IF failures detected, automatically investigate

## Output Format
[Format specifications]

## Phase 1: All Tests
[31 tests organized by category]

## Phase 2: Detailed Investigation Template
[Investigation format for failures]
```

### Migration Plan

1. **Create new prompt** based on existing `TESTING_PROMPTS_CLAUDE_DESKTOP.md`
2. **Preserve test cases** (same 31 tools, same test scenarios)
3. **Update output instructions** to lightweight format
4. **Add Phase 2 auto-trigger** instructions
5. **Test with User Testing** (single session)
6. **Iterate if needed** based on actual token usage

## Success Criteria

‚úÖ User Testing can paste ONE prompt
‚úÖ Walk away (unattended execution)
‚úÖ All 31 tools tested in single session
‚úÖ Failures get automatic detailed investigation
‚úÖ Total token usage < 60-70k (comfortable margin)

## Fallback Plan

If single session still doesn't work after optimization:
- **Split at natural boundary:** Tests 1-16 (queries) vs 17-31 (analytics/mutations)
- **Two separate prompts** with clear handoff
- **Still unattended per session**

## Notes

- Current test suite: 20/31 tests before hitting limits
- Token reduction needed: 60-70%
- Lightweight format achieves 75-80% reduction
- Phase 2 keeps debugging capability intact

---

## Implementation Results (2025-10-29)

**Attempt 1: Single-session lightweight format**
- Created `TESTING_PROMPTS_LIGHTWEIGHT.md`
- Result: Still hit limit at test 20-21 ‚ùå
- Issue: Claude added commentary between tests despite concise format

**Attempt 2: Stricter output instructions**
- Added "CRITICAL OUTPUT INSTRUCTIONS" with explicit "NO commentary" rules
- Result: Still hit limit at test 20-21 ‚ùå
- Issue: Not commentary - actual conversation length limit

**Final Solution: Two-session split** ‚úÖ
- Created `TESTING_PROMPTS_SESSION_1.md` (Tests 1-15)
- Created `TESTING_PROMPTS_SESSION_2.md` (Tests 16-31)
- Each session standalone, unattended per session
- Natural split: Core functionality vs Analytics/Advanced

**Lessons Learned:**
1. Lightweight format helps but isn't sufficient alone
2. Stricter instructions don't override fundamental token limits
3. Two-session approach is the reliable solution
4. 15-16 tests per session is comfortable margin
