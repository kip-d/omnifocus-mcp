# v1.16.0 Release Plan: Reality-Based Performance

## Mission Statement
Accept JXA's limitations and focus on user experience rather than chasing impossible performance targets.

## Priority 1: Fix the v1.15.0 Regression

### The Problem
- list_tasks went from 3.4s (v1.14.0) to 5.5s (v1.15.0)
- 62% performance regression is unacceptable

### Action Items
- [ ] Investigate what changed between v1.14.0 and v1.15.0
- [ ] Likely culprit: Additional processing without optimization benefit
- [ ] Rollback or fix the regression

## Priority 2: Set Realistic Expectations

### Update Documentation
```markdown
## Performance Expectations

With OmniFocus databases of:
- **< 500 tasks**: Sub-second responses ✅
- **500-1000 tasks**: 1-2 second responses ✅
- **1000-2000 tasks**: 2-3 second responses ⚠️
- **2000+ tasks**: 3-5 second responses ⚠️

These times are due to JXA bridge limitations, not this MCP server.
```

### Remove Misleading Claims
- [ ] Update README performance section
- [ ] Fix CHANGELOG v1.15.0 entry
- [ ] Update PERFORMANCE_TEST prompts with realistic targets

## Priority 3: Improve Perceived Performance

### 1. Progressive Loading
Instead of waiting 5 seconds for 500 tasks:
- Return first 50 tasks in <1 second
- Stream remaining tasks progressively
- User sees results immediately

### 2. Smarter Defaults
- Change default limit from 100 to 50
- Most users don't need 100 tasks at once
- 50 tasks = 2.5 seconds instead of 5 seconds

### 3. Cache Warming
- Pre-fetch common queries on startup:
  - Today's agenda
  - Overdue tasks
  - Flagged items
- Background refresh every 5 minutes

## Priority 4: Better Error Messages

Current: "Query timeout after 60 seconds"
Better: "Query is taking longer than expected. Consider reducing the limit or adding filters to narrow results."

## What NOT to Do in v1.16.0

### Don't Chase Micro-Optimizations
- ❌ Don't optimize list_tasks.ts safeGet calls (9% gain not worth it)
- ❌ Don't add more "ultra-optimized" script variants
- ❌ Don't promise sub-second performance

### Don't Add Complexity
- ❌ No hybrid architectures
- ❌ No evaluateJavascript experiments
- ❌ No parallel processing attempts (JXA is single-threaded)

## Proposed Changelog for v1.16.0

```markdown
## [1.16.0] - 2025-08-XX

### Fixed
- Restored v1.14.0 performance for list_tasks (3.4s for 100 tasks)
- Fixed misleading performance documentation
- Corrected tool descriptions for better LLM compatibility

### Changed
- Set realistic performance expectations in documentation
- Reduced default query limit from 100 to 50 for better UX
- Improved error messages for slow queries

### Added
- Cache warming for common queries
- Performance expectations guide based on database size

### Removed
- Unrealistic sub-second performance claims
- Misleading optimization promises

### Technical Notes
After extensive testing with real-world databases (2000+ tasks), we've identified that JXA's bridge overhead is the fundamental bottleneck. This release focuses on honest communication and user experience improvements rather than chasing unachievable performance targets.
```

## Success Metrics for v1.16.0

✅ **Achieved** if:
1. list_tasks performance restored to 3.4s (v1.14.0 level)
2. Documentation accurately reflects real performance
3. No more user complaints about "slow" being slower than advertised
4. Cache warming reduces perceived wait for common queries

❌ **Not Required**:
1. Sub-second performance (impossible with JXA)
2. Complex optimization schemes
3. Architectural changes (save for v2.0)

## Timeline

1. **Week 1**: Fix regression, update docs
2. **Week 2**: Implement cache warming
3. **Week 3**: Testing with real databases
4. **Week 4**: Release v1.16.0

## Long-term (v2.0) Considerations

If sub-second performance is truly required:
1. **Native Swift MCP server** using OmniFocus frameworks
2. **Direct SQLite access** (if possible without breaking terms)
3. **Local sync database** with background updates
4. **OmniAutomation plugin** that provides API endpoint

---

*Plan created: 2025-08-13*
*Focus: Reality over promises, UX over micro-optimizations*